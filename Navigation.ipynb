{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Start the Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityTimeOutException",
     "evalue": "The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Academy's Broadcast Hub is configured correctly\n\t The Agents are linked to the appropriate Brains\n\t The environment and the Python interface have compatible versions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a9df97e756d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# env = UnityEnvironment(file_name=\"Banana\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./envs/%s/%s.x86_64\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_graphics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml-agents/lib/python3.6/site-packages/mlagents/envs/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, seed, docker_training, no_graphics, timeout_wait, args)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrl_init_parameters_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityRLInitializationInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-agents/lib/python3.6/site-packages/mlagents/envs/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-agents/lib/python3.6/site-packages/mlagents/envs/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout_wait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"\\t The environment does not need user interaction to launch\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"\\t The Academy's Broadcast Hub is configured correctly\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m: The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Academy's Broadcast Hub is configured correctly\n\t The Agents are linked to the appropriate Brains\n\t The environment and the Python interface have compatible versions."
     ]
    }
   ],
   "source": [
    "from mlagents.envs.environment import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import summary\n",
    "from pympler import muppy\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "\n",
    "# env_name = 'maze_architecture_win'\n",
    "# env_name = 'aug_22_vcs'\n",
    "# env_name = 'sep_1_vcs'\n",
    "# env_name = 'sep_1_banana'\n",
    "# env_name = 'sep_28'\n",
    "env_name = 'oct_20_linux'\n",
    "\n",
    "# env = UnityEnvironment(file_name=\"Banana\")\n",
    "env = UnityEnvironment(file_name=\"./envs/%s/%s.x86_64\" % (env_name, env_name), worker_id=1, seed=1, no_graphics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "brain_name, brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of agents in the environment\n",
    "# print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(env_info.visual_observations)\n",
    "imgplt = plt.imshow(img[0][0])\n",
    "height, width, channel = img[0][0].shape\n",
    "height, width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.nn.functional'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-419c0cff8ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/scl-navigation/agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from model import QNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdqn_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/scl-navigation/dqn_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.nn.functional'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "from collections import deque\n",
    "from agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "model_weight_name = 'checkpoint.pth'\n",
    "agent = Agent(state_size=300, action_size=9, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = 8\n",
    "# state = np.transpose(np.asarray(env_info.visual_observations)[0][0], (2, 0, 1))\n",
    "# action_transformed = get_action(action)\n",
    "# print(action_transformed)\n",
    "\n",
    "# reward = env_info.rewards[0]\n",
    "# done = env_info.local_done[0]\n",
    "\n",
    "# env_info = env.step(action_transformed)[brain_name]\n",
    "# next_state = np.transpose(np.asarray(env_info.visual_observations)[0][0], (2, 0, 1))\n",
    "# agent.step(state, action, reward, next_state, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DQN Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(action):\n",
    "    move_forward  = action // 3\n",
    "    rotate = action % 3\n",
    "    return [move_forward, rotate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "from pympler.tracker import SummaryTracker\n",
    "\n",
    "def dqn(env_info, n_episodes=1, max_t=2000, eps_start=1.0, eps_end=0.01, \n",
    "        eps_decay=0.995, target_scores=1.0, video_flag=True):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        target_scores (float): average scores aming to achieve, the agent will stop training once it reaches this scores\n",
    "        video_flag (boolean): a flag for whether to record video, if set to True, video would be recorded for every 20 episodes\n",
    "    \n",
    "    Returns\n",
    "    ======\n",
    "        scores in 2-d array\n",
    "        positions in 2-d array\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()                       # Start time\n",
    "    scores = []                               # list containing scores from each episode\n",
    "    positions = []                            # position list\n",
    "    scores_window = deque(maxlen=100)         # last 100 scores\n",
    "    eps = eps_start                           # initialize epsilon\n",
    "    width, height, channel = [300, 300, 3]\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        video_flag = (i_episode % 20 == 1)\n",
    "        \n",
    "        # start video recording \n",
    "        if video_flag:\n",
    "            fourcc = cv2.VideoWriter_fourcc('M','S','V','C') #Microspoft Video 1\n",
    "            video  = cv2.VideoWriter('output_sep_18_%s.avi' % (str(i_episode)), fourcc, 30, (width, height))\n",
    "            \n",
    "        # Reset env and score at the beginning of episode\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment        \n",
    "        state = np.transpose(np.asarray(env_info.visual_observations)[0][0], (2, 0, 1))  # get the current visual state\n",
    "        score = 0                                               # initialize the score\n",
    "        position_epi = []\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            \n",
    "            if video_flag:\n",
    "                video.write(np.asarray(env_info.visual_observations)[0][0])\n",
    "                \n",
    "            action = agent.act(state, eps)\n",
    "            \n",
    "            # translate action variable into forward, rotate, and right\n",
    "            action_transformed = get_action(action)\n",
    "            env_info = env.step(action_transformed)[brain_name]        # send the action to the environment\n",
    "            next_state = np.transpose(np.asarray(env_info.visual_observations)[0][0], \n",
    "                                      (2, 0, 1)) # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            position_epi.append(env_info.vector_observations[0][-3:].tolist())\n",
    "            \n",
    "            stdout.write('\\r t:{}, position:{}, score:{:.3f}'.format(str(t), \n",
    "                                    str(env_info.vector_observations[0][-3:]), score))\n",
    "            stdout.flush()\n",
    "                        \n",
    "            # for testing purpose\n",
    "            if done:\n",
    "                print('\\n!!!!!done\\n')\n",
    "                break\n",
    "        \n",
    "        writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
    "                                'xcosx':i*np.cos(i/r),\n",
    "                                'tanx': np.tan(i/r)}, i)\n",
    "\n",
    "        \n",
    "        positions.append(position_epi)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        \n",
    "        print('\\nEpisode {}\\tAverage Score: {:.2f}\\t Last Move {}\\n'.format(i_episode, \n",
    "                                                            np.mean(scores_window), action_transformed), end=\"\")\n",
    "        if i_episode % 10 == 0:\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'model_%s' % str(i_episode))\n",
    "\n",
    "        # if np.mean(scores_window)>=target_scores:\n",
    "        #     print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, \n",
    "        #                                                                      np.mean(scores_window)))\n",
    "        #     torch.save(agent.qnetwork_local.state_dict(), model_weight_name)\n",
    "        #     break\n",
    "        \n",
    "        if video_flag:\n",
    "            cv2.destroyAllWindows()\n",
    "            video.release()\n",
    "    \n",
    "    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "    torch.save(agent.qnetwork_local.state_dict(), model_weight_name)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print(\"Time Elapse: {:.2f}\".format(time_elapsed))\n",
    "    \n",
    "    return scores, positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ab06e5b65dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scores, positions = dqn(env_info, n_episodes=100, max_t=200, eps_start=1.0, \n\u001b[0m\u001b[1;32m      2\u001b[0m                         eps_end=0.01, eps_decay=0.995, target_scores=1.0, video_flag=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env_info' is not defined"
     ]
    }
   ],
   "source": [
    "scores, positions = dqn(env_info, n_episodes=100, max_t=200, eps_start=1.0, \n",
    "                        eps_end=0.01, eps_decay=0.995, target_scores=1.0, video_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = [[-252.8, -26.6, 118.7], [-184.0, -25.9, 89.9], \n",
    "         [-121.3, -19.5, 3.8], [-162.1, -27.1, 13.3], [-202.0, -27.3, 11.1],\n",
    "        [40.9, -20.75, -30.8], [75.5, -28.1, -38.7]]\n",
    "goals = [[i[0] - 388.5, i[1] + 24.4, i[2] + 80.5] for i in goals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [positions[0][0][0], positions[0][0][1], positions[0][0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "for i in range(len(positions)):\n",
    "    # ignore the last item, as it might start from the origin\n",
    "    a = [[a[0], a[1], a[2]] for a in positions[i]]\n",
    "    pos.append(np.asarray(a[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final_goal = [-382.46, 54.69, 4]\n",
    "final_goal = [-342.9, 3.65, 48.0]\n",
    "for i in range(len(pos)):\n",
    "    plt.plot(pos[i][:,0], pos[i][:,2])\n",
    "#     break\n",
    "\n",
    "for i in range(len(goals)):\n",
    "    plt.plot(goals[i][0], goals[i][2], marker='o', markersize=10, color=\"grey\")\n",
    "\n",
    "plt.plot([final_goal[0]], [final_goal[2]], marker='o', markersize=40, color=\"black\")\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.expand_dims(np.asarray(env_info.visual_observations)[0][0], axis=0)\n",
    "input = np.transpose(imgs, (0, 3, 1, 2))\n",
    "input = np.concatenate([input, input, input, input], 0)\n",
    "print(input.shape)\n",
    "\n",
    "m1  = torch.nn.Conv2d(3, 32, kernel_size=8, stride=4)\n",
    "m2  = torch.nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "m3  = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "fc4 = torch.nn.Linear(34 * 34 * 64, 512)\n",
    "fc5 = torch.nn.Linear(512, 9)\n",
    "\n",
    "input = torch.randn(1, 3, 300, 300)\n",
    "output1 = m1(input)\n",
    "print(output1.shape)\n",
    "output2 = m2(output1)\n",
    "print(output2.shape)\n",
    "output3 = torch.flatten(m3(output2))\n",
    "print(output3.shape)\n",
    "output4 = fc4(output3)\n",
    "print(output4.shape)\n",
    "output5 = fc5(output4)\n",
    "\n",
    "# fc5(fc4(m3(m2(m1(input)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 300, 300)\n",
    "input = input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(env_info.visual_observations)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the scores\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.plot(np.arange(len(scores)), scores)\n",
    "# plt.ylabel('Score')\n",
    "# plt.xlabel('Episode #')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.chck[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.qnetwork_local(agent.chck[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch the agent running ( Using saved weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load(model_weight_name))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Unity ML Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
